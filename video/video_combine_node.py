import os
import subprocess
import numpy as np
import tempfile
import json
from typing import List, Dict, Any
import torch
import folder_paths
from comfy.utils import ProgressBar

def tensor_to_int(tensor, bits):
    tensor = tensor.cpu().numpy() * (2**bits-1) + 0.5
    return np.clip(tensor, 0, (2**bits-1))

def tensor_to_shorts(tensor):
    return tensor_to_int(tensor, 16).astype(np.uint16)

def tensor_to_bytes(tensor):
    return tensor_to_int(tensor, 8).astype(np.uint8)

def ffmpeg_process(args, video_format, video_metadata, file_path, env, total_frames=None):
    import json
    
    res = None
    frame_data = yield
    total_frames_output = 0
    
    # å¤„ç†å…ƒæ•°æ®ä¿å­˜ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if video_format.get('save_metadata', 'False') != 'False':
        os.makedirs(folder_paths.get_temp_directory(), exist_ok=True)
        metadata = json.dumps(video_metadata)
        metadata_path = os.path.join(folder_paths.get_temp_directory(), "metadata.txt")
        # è½¬ä¹‰å…ƒæ•°æ®ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        metadata = metadata.replace("\\","\\\\")
        metadata = metadata.replace(";","\\;")
        metadata = metadata.replace("#","\\#")
        metadata = metadata.replace("=","\\=")
        metadata = metadata.replace("\n","\\\n")
        metadata = "comment=" + metadata
        with open(metadata_path, "w") as f:
            f.write(";FFMETADATA1\n")
            f.write(metadata)
        m_args = args[:1] + ["-i", metadata_path] + args[1:] + ["-metadata", "creation_time=now"]
        
        with subprocess.Popen(m_args + [file_path], stderr=subprocess.PIPE,
                              stdin=subprocess.PIPE, env=env) as proc:
            try:
                while frame_data is not None:
                    proc.stdin.write(frame_data)
                    frame_data = yield
                    total_frames_output += 1
                proc.stdin.flush()
                proc.stdin.close()
                res = proc.stderr.read()
            except BrokenPipeError as e:
                err = proc.stderr.read()
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(file_path):
                    os.remove(file_path)
                raise Exception("An error occurred in the ffmpeg subprocess:\n" + err.decode('utf-8', errors='ignore'))
    
    # å¦‚æœå…ƒæ•°æ®å¤„ç†å¤±è´¥æˆ–ä¸éœ€è¦å…ƒæ•°æ®ï¼Œä½¿ç”¨æ ‡å‡†å¤„ç†
    if res != b'':
        with subprocess.Popen(args + [file_path], stderr=subprocess.PIPE,
                              stdin=subprocess.PIPE, env=env) as proc:
            try:
                while frame_data is not None:
                    proc.stdin.write(frame_data)
                    frame_data = yield
                    total_frames_output += 1
                proc.stdin.flush()
                proc.stdin.close()
                res = proc.stderr.read()
            except BrokenPipeError as e:
                res = proc.stderr.read()
                if os.path.exists(file_path):
                    os.remove(file_path)
                raise Exception("An error occurred in the ffmpeg subprocess:\n" + res.decode('utf-8', errors='ignore'))
    
    yield total_frames_output
    if len(res) > 0:
        print(res.decode('utf-8', errors='ignore'), end="")

class VideoCombineNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "images": ("IMAGE",),
                "frame_rate": ("FLOAT", {"default": 16.0, "min": 0.01, "max": 1000.0, "step": 0.01}),
                "filename": ("STRING", {"default": "video_output"}),
                "pix_fmt": (["yuv420p", "yuv420p10le", "yuv422p", "yuv444p", "rgb24", "rgba"], {"default": "yuv420p"}),
                "crf": ("INT", {"default": 19, "min": 0, "max": 51, "step": 1}),
                "save_metadata": ("BOOLEAN", {"default": True}),
                "trim_to_audio": ("BOOLEAN", {"default": False}),
                "last_frames_count": ("INT", {"default": 0, "min": 0, "max": 100, "step": 1}),
            },
            "optional": {
                "audio": ("AUDIO",),
                "pingpong": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "IMAGE")
    RETURN_NAMES = ("video_path", "filename", "last_frames_images")
    OUTPUT_NODE = True
    CATEGORY = "lianlaoshi/video"
    FUNCTION = "combine_video"

    def combine_video(
        self,
        images,
        frame_rate: float,
        filename: str,
        pix_fmt: str = "yuv420p",
        crf: int = 19,
        save_metadata: bool = True,
        trim_to_audio: bool = False,
        last_frames_count: int = 0,
        audio=None,
        pingpong: bool = False,
        **kwargs
    ):
        # å¤„ç†è¾“å…¥æ•°æ®
        batched_output = images

        # å¤„ç†pingpongæ•ˆæœ
        if pingpong:
            batched_output = torch.cat([batched_output, batched_output[1:-1].flip(0)], dim=0)

        # è·å–æ€»å¸§æ•°ç”¨äºè¿›åº¦æ¡
        total_frames = len(batched_output)

        # è·å–è¾“å‡ºç›®å½•
        output_dir = folder_paths.get_output_directory()
        
        # ç”Ÿæˆæ–‡ä»¶å - ç›´æ¥ä½¿ç”¨mp4æ‰©å±•å
        counter = 1
        extension = "mp4"
        while True:
            full_filename = f"{filename}_{counter:05d}.{extension}"
            file_path = os.path.join(output_dir, full_filename)
            if not os.path.exists(file_path):
                break
            counter += 1

        # å‡†å¤‡è§†é¢‘å…ƒæ•°æ®
        dimensions = f"{batched_output.shape[2]}x{batched_output.shape[1]}"
        
        # åˆ›å»ºå¸§ç”Ÿæˆå™¨ï¼Œè½¬æ¢ä¸ºå­—èŠ‚æ•°æ®ï¼ˆåŒ¹é…VHSå®ç°ï¼‰
        def frame_generator():
            for i, image in enumerate(batched_output):
                # è½¬æ¢tensoråˆ°numpyæ•°ç»„
                img_array = 255. * image.cpu().numpy()
                img = np.clip(img_array, 0, 255).astype(np.uint8)
                yield img.tobytes()  # ç›´æ¥è¿”å›å­—èŠ‚æ•°æ®

        video_metadata = {
            "frame_rate": frame_rate,
            "filename": filename,
        }

        # æ„å»ºFFmpegå‘½ä»¤ï¼Œå‚è€ƒVHSåŸå§‹å®ç°
        args = [
            "ffmpeg", "-v", "error", "-f", "rawvideo", "-pix_fmt", "rgb24",
            "-color_range", "pc", "-colorspace", "rgb", "-color_primaries", "bt709",
            "-color_trc", "iec61966-2-1",
            "-s", dimensions, "-r", str(frame_rate), "-i", "-",
            "-c:v", "libx264",
            "-pix_fmt", pix_fmt,
            "-crf", str(crf),
            "-preset", "medium"
        ]
        
        # æ·»åŠ éŸ³é¢‘å¤„ç†ï¼ˆæš‚æ—¶ç¦ç”¨ï¼‰
        args.extend(["-an"])

        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        
        # æ„å»ºvideo_formatç”¨äºffmpeg_process
        video_format = {
            "extension": extension,
            "save_metadata": str(save_metadata)
        }
        

        
        # å¤„ç†éŸ³é¢‘åˆå¹¶ï¼ˆå‚è€ƒVHSåŸå§‹å®ç°ï¼‰
        final_file_path = file_path
        final_filename = full_filename
        
        if audio is not None:
            # æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
            a_waveform = None
            try:
                a_waveform = audio['waveform']
            except:
                pass
            
            if a_waveform is not None:
                # å…ˆç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘
                output_process = ffmpeg_process(args, video_format, video_metadata, file_path, env, total_frames)
                output_process.send(None)  # å¯åŠ¨ç”Ÿæˆå™¨
                
                # åˆ›å»ºè¿›åº¦æ¡
                pbar = ProgressBar(total_frames)
                
                # å‘é€å¸§æ•°æ®
                for frame_bytes in frame_generator():
                    pbar.update(1)
                    output_process.send(frame_bytes)
                
                # å®Œæˆå¤„ç†
                try:
                    total_frames_output = output_process.send(None)
                    output_process.send(None)
                except StopIteration:
                    pass
                
                # ç„¶ååˆå¹¶éŸ³é¢‘ï¼ˆå‚è€ƒVHSåŸå§‹å®ç°ï¼‰
                try:
                    # ä¸ºéŸ³é¢‘æ–‡ä»¶å•ç‹¬æ£€æŸ¥æ–‡ä»¶åï¼Œç¡®ä¿ä¸ä¼šè¦†ç›–ç°æœ‰æ–‡ä»¶
                    audio_counter = 1
                    while True:
                        output_file_with_audio = f"{filename}_{audio_counter:05d}-audio.mp4"
                        output_file_with_audio_path = os.path.join(output_dir, output_file_with_audio)
                        if not os.path.exists(output_file_with_audio_path):
                            break
                        audio_counter += 1
                    
                    # è®¾ç½®éŸ³é¢‘ç¼–ç å‚æ•°
                    audio_pass = ["-c:a", "aac"]  # ä½¿ç”¨AACéŸ³é¢‘ç¼–ç 
                    
                    # è·å–éŸ³é¢‘å‚æ•°
                    channels = audio['waveform'].size(1)
                    sample_rate = audio['sample_rate']
                    min_audio_dur = total_frames / frame_rate + 1
                    
                    # è®¾ç½®éŸ³é¢‘å¡«å……å‚æ•°
                    if trim_to_audio:
                        apad = []
                    else:
                        apad = ["-af", f"apad=whole_dur={min_audio_dur}"]
                    
                    # æŸ¥æ‰¾FFmpegè·¯å¾„
                    import subprocess
                    import shutil
                    
                    ffmpeg_path = shutil.which("ffmpeg")
                    if not ffmpeg_path:
                        # å°è¯•å¸¸è§è·¯å¾„
                        possible_paths = [
                            "ffmpeg",
                            "ffmpeg.exe",
                            os.path.join(os.path.dirname(sys.executable), "ffmpeg.exe"),
                            os.path.join(os.path.dirname(sys.executable), "Scripts", "ffmpeg.exe")
                        ]
                        for path in possible_paths:
                            if shutil.which(path):
                                ffmpeg_path = path
                                break
                        else:
                            raise Exception("FFmpeg not found in system PATH")
                    
                    # æ„å»ºFFmpegå‘½ä»¤ï¼ˆå‚è€ƒVHSå®ç°ï¼‰
                    mux_args = [ffmpeg_path, "-v", "error", "-y", "-i", file_path,
                               "-ar", str(sample_rate), "-ac", str(channels),
                               "-f", "f32le", "-i", "-", "-c:v", "copy"] \
                               + audio_pass + apad + ["-shortest", output_file_with_audio_path]
                    
                    # å‡†å¤‡éŸ³é¢‘æ•°æ®
                    audio_data = audio['waveform'].squeeze(0).transpose(0,1).numpy().tobytes()
                    
                    # æ‰§è¡ŒFFmpegå‘½ä»¤
                    res = subprocess.run(mux_args, input=audio_data, 
                                       capture_output=True, check=True)
                    
                    if res.stderr:
                        print(res.stderr.decode('utf-8'), end="")
                    
                    final_file_path = output_file_with_audio_path
                    final_filename = output_file_with_audio
                    
                    # åˆ é™¤æ— éŸ³é¢‘ç‰ˆæœ¬çš„æ–‡ä»¶ï¼ˆå®ç°VHS_KeepIntermediate=Falseçš„æ•ˆæœï¼‰
                    try:
                        if os.path.exists(file_path):
                            os.remove(file_path)
                    except Exception as remove_error:
                        pass
                    
                except Exception as e:
                    # ä¸ç”Ÿæˆæ— éŸ³é¢‘ç‰ˆæœ¬ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
                    raise Exception(f"éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå¸¦éŸ³é¢‘çš„è§†é¢‘: {str(e)}")
            else:
                # æ²¡æœ‰æœ‰æ•ˆéŸ³é¢‘æ•°æ®ï¼Œç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘
                output_process = ffmpeg_process(args, video_format, video_metadata, file_path, env, total_frames)
                output_process.send(None)  # å¯åŠ¨ç”Ÿæˆå™¨
                
                # åˆ›å»ºè¿›åº¦æ¡
                pbar = ProgressBar(total_frames)
                
                # å‘é€å¸§æ•°æ®
                for frame_bytes in frame_generator():
                    pbar.update(1)
                    output_process.send(frame_bytes)
                
                # å®Œæˆå¤„ç†
                try:
                    total_frames_output = output_process.send(None)
                    output_process.send(None)
                except StopIteration:
                    pass
        else:
            # æ²¡æœ‰éŸ³é¢‘è¾“å…¥ï¼Œç”Ÿæˆæ— éŸ³é¢‘è§†é¢‘
            output_process = ffmpeg_process(args, video_format, video_metadata, file_path, env, total_frames)
            output_process.send(None)  # å¯åŠ¨ç”Ÿæˆå™¨
            
            # åˆ›å»ºè¿›åº¦æ¡
            pbar = ProgressBar(total_frames)
            
            # å‘é€å¸§æ•°æ®
            for frame_bytes in frame_generator():
                pbar.update(1)
                output_process.send(frame_bytes)
            
            # å…³é—­ç®¡é“å¹¶ç­‰å¾…å®Œæˆ
            try:
                total_frames_output = output_process.send(None)
                output_process.send(None)
            except StopIteration:
                pass
        
        # è·å–æœ€åå‡ å¸§å›¾åƒ
        if last_frames_count > 0 and len(batched_output) > 0:
            start_idx = max(0, len(batched_output) - last_frames_count)
            last_frames_images = batched_output[start_idx:]
        else:
            # å¦‚æœä¸éœ€è¦æœ€åå‡ å¸§æˆ–æ²¡æœ‰å›¾åƒï¼Œè¿”å›ç©ºçš„tensor
            if len(batched_output) > 0:
                last_frames_images = torch.empty(0, *batched_output.shape[1:])
            else:
                # åˆ›å»ºä¸€ä¸ªé»˜è®¤å½¢çŠ¶çš„ç©ºtensor
                last_frames_images = torch.empty(0, 3, 512, 512)  # é»˜è®¤å½¢çŠ¶

        return (final_file_path, final_filename, last_frames_images)
    

class VideoMergeNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "video_paths": ("STRING", {
                    "multiline": True,
                    "tooltip": "è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒå¤šè¡Œè¾“å…¥æˆ–é€—å·åˆ†éš”çš„å¤šä¸ªè·¯å¾„"
                }),
                "output_filename": ("STRING", {
                    "default": "merged_video.mp4",
                    "tooltip": "è¾“å‡ºåˆæˆè§†é¢‘çš„æ–‡ä»¶å"
                }),
            },
            "optional": {
                "audio": ("AUDIO", {
                    "tooltip": "å¯é€‰çš„èƒŒæ™¯éŸ³é¢‘ï¼Œå¦‚æœæä¾›åˆ™æ›¿æ¢è§†é¢‘éŸ³é¢‘ï¼Œå¦åˆ™ä¿ç•™åŸéŸ³é¢‘"
                }),
                "video_paths_list": ("*", {
                    "tooltip": "å¯é€‰çš„è§†é¢‘è·¯å¾„åˆ—è¡¨è¾“å…¥ï¼Œå¦‚æœæä¾›åˆ™ä¼˜å…ˆä½¿ç”¨æ­¤è¾“å…¥"
                }),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("video_path",)
    OUTPUT_NODE = True
    CATEGORY = "lianlaoshi/video"
    FUNCTION = "merge_videos"

    def __init__(self):
        self.ffmpeg_path = self._find_ffmpeg()

    def _find_ffmpeg(self) -> str:
        """æŸ¥æ‰¾FFmpegå¯æ‰§è¡Œæ–‡ä»¶"""
        # æ£€æŸ¥å¸¸è§è·¯å¾„
        possible_paths = [
            "ffmpeg",  # ç³»ç»ŸPATHä¸­
            "ffmpeg.exe",  # Windows
            r"C:\ffmpeg\bin\ffmpeg.exe",  # å¸¸è§Windowså®‰è£…è·¯å¾„
            "/usr/bin/ffmpeg",  # Linux
            "/usr/local/bin/ffmpeg",  # macOS
        ]
        
        for path in possible_paths:
            try:
                result = subprocess.run([path, "-version"], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    return path
            except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
                continue
        
        raise RuntimeError("FFmpeg not found. Please install FFmpeg and ensure it's in your PATH.")

    def _validate_video_files(self, video_paths: List[str]) -> List[str]:
        """éªŒè¯è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ"""
        if not video_paths:
            raise ValueError("è§†é¢‘è·¯å¾„åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•åˆå¹¶")
        
        # é¦–å…ˆæ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœæœ‰ä»»ä½•æ–‡ä»¶ä¸å­˜åœ¨å°±ç«‹å³å¤±è´¥
        missing_files = []
        for path in video_paths:
            if not os.path.exists(path):
                missing_files.append(path)
                continue
            
            if not os.path.isfile(path):
                missing_files.append(path)
                continue
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(path)
            if file_size == 0:
                missing_files.append(path)
                continue
        
        # å¦‚æœæœ‰ä»»ä½•æ–‡ä»¶ç¼ºå¤±ï¼ŒæŠ›å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        if missing_files:
            error_msg = f"å‘ç° {len(missing_files)} ä¸ªæ— æ•ˆæˆ–ç¼ºå¤±çš„è§†é¢‘æ–‡ä»¶:\n"
            for file in missing_files:
                error_msg += f"  - {file}\n"
            error_msg += "\nè¯·ç¡®ä¿æ‰€æœ‰è§†é¢‘æ–‡ä»¶éƒ½å­˜åœ¨ä¸”ä¸ä¸ºç©ºã€‚"
            raise FileNotFoundError(error_msg)
        
        return video_paths

    def _get_audio_duration(self, audio_data) -> float:
        """è·å–éŸ³é¢‘æ•°æ®çš„æ—¶é•¿ï¼ˆç§’ï¼‰"""
        try:
            if audio_data is None:
                return 0.0
            
            # å¤„ç†LazyAudioMapæ ¼å¼
            if hasattr(audio_data, '__class__') and 'LazyAudioMap' in str(audio_data.__class__):
                try:
                    # å°è¯•è·å–waveformå’Œsample_rateå±æ€§
                    if hasattr(audio_data, 'waveform') and hasattr(audio_data, 'sample_rate'):
                        waveform = audio_data.waveform
                        sample_rate = audio_data.sample_rate
                    # å°è¯•å­—å…¸å¼è®¿é—®
                    elif hasattr(audio_data, '__getitem__'):
                        waveform = audio_data['waveform']
                        sample_rate = audio_data['sample_rate']
                    # å°è¯•è°ƒç”¨get_audioæˆ–loadæ–¹æ³•
                    elif hasattr(audio_data, 'get_audio'):
                        result = audio_data.get_audio()
                        waveform = result['waveform'] if isinstance(result, dict) else result[0]
                        sample_rate = result['sample_rate'] if isinstance(result, dict) else result[1]
                    elif hasattr(audio_data, 'load'):
                        result = audio_data.load()
                        waveform = result['waveform'] if isinstance(result, dict) else result[0]
                        sample_rate = result['sample_rate'] if isinstance(result, dict) else result[1]
                    else:
                        return 0.0
                    
                    # å¤„ç†æå–çš„éŸ³é¢‘æ•°æ®
                    audio_data = {"waveform": waveform, "sample_rate": sample_rate}
                except Exception as e:
                    return 0.0
            
            # å¤„ç†å­—å…¸æ ¼å¼ {"waveform": tensor, "sample_rate": int}
            if isinstance(audio_data, dict):
                waveform = audio_data.get("waveform")
                sample_rate = audio_data.get("sample_rate", 44100)
                
                if waveform is None:
                    return 0.0
                    
                # ç»Ÿä¸€å¤„ç†waveformç»´åº¦
                if hasattr(waveform, 'shape'):
                    # å¤„ç†ä¸åŒç»´åº¦çš„éŸ³é¢‘æ•°æ®
                    if len(waveform.shape) == 1:
                        # 1D: [samples] -> è½¬æ¢ä¸º [1, samples]
                        samples = waveform.shape[0]
                    elif len(waveform.shape) == 2:
                        # 2D: å¯èƒ½æ˜¯ [samples, channels] æˆ– [channels, samples]
                        # é€šå¸¸channelsæ•°é‡è¾ƒå°‘ï¼Œsamplesæ•°é‡è¾ƒå¤š
                        if waveform.shape[0] <= waveform.shape[1]:
                            # [channels, samples] æ ¼å¼
                            samples = waveform.shape[1]
                        else:
                            # [samples, channels] æ ¼å¼ï¼Œéœ€è¦è½¬ç½®
                            samples = waveform.shape[0]
                    elif len(waveform.shape) == 3:
                        # 3D: [batch, channels, samples] æˆ– [batch, samples, channels]
                        if waveform.shape[1] <= waveform.shape[2]:
                            # [batch, channels, samples] æ ¼å¼
                            samples = waveform.shape[2]
                        else:
                            # [batch, samples, channels] æ ¼å¼
                            samples = waveform.shape[1]
                    else:
                        # æ›´é«˜ç»´åº¦ï¼Œå–æœ€åä¸€ä¸ªç»´åº¦ä½œä¸ºsamples
                        samples = waveform.shape[-1]
                else:
                    # å¦‚æœæ²¡æœ‰shapeå±æ€§ï¼Œå°è¯•è·å–é•¿åº¦
                    samples = len(waveform) if hasattr(waveform, '__len__') else 0
                    
                return samples / sample_rate if sample_rate > 0 else 0.0
            
            # å¤„ç†å…ƒç»„æ ¼å¼ (waveform, sample_rate)
            elif isinstance(audio_data, (tuple, list)) and len(audio_data) >= 2:
                waveform, sample_rate = audio_data[0], audio_data[1]
                
                # ç»Ÿä¸€å¤„ç†waveformç»´åº¦
                if hasattr(waveform, 'shape'):
                    # å¤„ç†ä¸åŒç»´åº¦çš„éŸ³é¢‘æ•°æ®
                    if len(waveform.shape) == 1:
                        # 1D: [samples] -> è½¬æ¢ä¸º [1, samples]
                        samples = waveform.shape[0]
                    elif len(waveform.shape) == 2:
                        # 2D: å¯èƒ½æ˜¯ [samples, channels] æˆ– [channels, samples]
                        # é€šå¸¸channelsæ•°é‡è¾ƒå°‘ï¼Œsamplesæ•°é‡è¾ƒå¤š
                        if waveform.shape[0] <= waveform.shape[1]:
                            # [channels, samples] æ ¼å¼
                            samples = waveform.shape[1]
                        else:
                            # [samples, channels] æ ¼å¼ï¼Œéœ€è¦è½¬ç½®
                            samples = waveform.shape[0]
                    elif len(waveform.shape) == 3:
                        # 3D: [batch, channels, samples] æˆ– [batch, samples, channels]
                        if waveform.shape[1] <= waveform.shape[2]:
                            # [batch, channels, samples] æ ¼å¼
                            samples = waveform.shape[2]
                        else:
                            # [batch, samples, channels] æ ¼å¼
                            samples = waveform.shape[1]
                    else:
                        # æ›´é«˜ç»´åº¦ï¼Œå–æœ€åä¸€ä¸ªç»´åº¦ä½œä¸ºsamples
                        samples = waveform.shape[-1]
                else:
                    # å¦‚æœæ²¡æœ‰shapeå±æ€§ï¼Œå°è¯•è·å–é•¿åº¦
                    samples = len(waveform) if hasattr(waveform, '__len__') else 0
                
                return samples / sample_rate if sample_rate > 0 else 0.0
            
            # å¤„ç†ç›´æ¥çš„tensoræ ¼å¼
            elif hasattr(audio_data, 'shape'):
                # å‡è®¾é‡‡æ ·ç‡ä¸º44100ï¼Œè¿™æ˜¯ä¸€ä¸ªé»˜è®¤å€¼
                sample_rate = 44100
                
                # ç»Ÿä¸€å¤„ç†waveformç»´åº¦
                if len(audio_data.shape) == 1:
                    # 1D: [samples] -> è½¬æ¢ä¸º [1, samples]
                    samples = audio_data.shape[0]
                elif len(audio_data.shape) == 2:
                    # 2D: å¯èƒ½æ˜¯ [samples, channels] æˆ– [channels, samples]
                    # é€šå¸¸channelsæ•°é‡è¾ƒå°‘ï¼Œsamplesæ•°é‡è¾ƒå¤š
                    if audio_data.shape[0] <= audio_data.shape[1]:
                        # [channels, samples] æ ¼å¼
                        samples = audio_data.shape[1]
                    else:
                        # [samples, channels] æ ¼å¼ï¼Œéœ€è¦è½¬ç½®
                        samples = audio_data.shape[0]
                elif len(audio_data.shape) == 3:
                    # 3D: [batch, channels, samples] æˆ– [batch, samples, channels]
                    if audio_data.shape[1] <= audio_data.shape[2]:
                        # [batch, channels, samples] æ ¼å¼
                        samples = audio_data.shape[2]
                    else:
                        # [batch, samples, channels] æ ¼å¼
                        samples = audio_data.shape[1]
                else:
                    # æ›´é«˜ç»´åº¦ï¼Œå–æœ€åä¸€ä¸ªç»´åº¦ä½œä¸ºsamples
                    samples = audio_data.shape[-1]
                
                return samples / sample_rate
            
            else:
                return 0.0
                
        except Exception as e:
            return 0.0

    def _save_audio_to_temp(self, audio_data) -> str:
        """ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œä½¿ç”¨scipy.io.wavfileç¡®ä¿å…¼å®¹æ€§"""
        if audio_data is None:
            return ""
        
        try:
            import tempfile
            import scipy.io.wavfile
            
            waveform = None
            sample_rate = 44100
            
            # å¤„ç†LazyAudioMapæ ¼å¼
            if hasattr(audio_data, '__class__') and 'LazyAudioMap' in str(audio_data.__class__):
                try:
                    # å°è¯•è·å–waveformå’Œsample_rateå±æ€§
                    if hasattr(audio_data, 'waveform') and hasattr(audio_data, 'sample_rate'):
                        waveform = audio_data.waveform
                        sample_rate = audio_data.sample_rate
                    # å°è¯•å­—å…¸å¼è®¿é—®
                    elif hasattr(audio_data, '__getitem__'):
                        try:
                            waveform = audio_data['waveform']
                            sample_rate = audio_data['sample_rate']
                        except:
                            waveform = None
                    # å°è¯•è°ƒç”¨get_audioæˆ–loadæ–¹æ³•
                    elif hasattr(audio_data, 'get_audio'):
                        result = audio_data.get_audio()
                        waveform = result['waveform'] if isinstance(result, dict) else result[0]
                        sample_rate = result['sample_rate'] if isinstance(result, dict) else result[1]
                    elif hasattr(audio_data, 'load'):
                        result = audio_data.load()
                        waveform = result['waveform'] if isinstance(result, dict) else result[0]
                        sample_rate = result['sample_rate'] if isinstance(result, dict) else result[1]
                    
                    # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ç›´æ¥è½¬æ¢
                    if waveform is None:
                        return ""
                    
                    # å¤„ç†æå–çš„éŸ³é¢‘æ•°æ®
                    audio_data = {"waveform": waveform, "sample_rate": sample_rate}
                except Exception as e:
                    return ""
            
            # å¤„ç†ä¸åŒçš„éŸ³é¢‘æ•°æ®æ ¼å¼
            if isinstance(audio_data, dict):
                # æ ‡å‡†æ ¼å¼ï¼š{"waveform": tensor, "sample_rate": int}
                waveform = audio_data.get("waveform")
                sample_rate = audio_data.get("sample_rate", 44100)
            elif isinstance(audio_data, (list, tuple)) and len(audio_data) >= 2:
                # å…ƒç»„/åˆ—è¡¨æ ¼å¼ï¼š(waveform, sample_rate)
                waveform = audio_data[0]
                sample_rate = audio_data[1] if len(audio_data) > 1 else 44100
            elif hasattr(audio_data, 'shape'):
                # ç›´æ¥æ˜¯tensoræ ¼å¼
                waveform = audio_data
                sample_rate = 44100
            else:
                return ""
            
            if waveform is None:
                return ""
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            if hasattr(waveform, 'cpu'):
                waveform = waveform.cpu()
            if hasattr(waveform, 'numpy'):
                waveform = waveform.numpy()
            
            # å¤„ç†ä¸åŒç»´åº¦çš„éŸ³é¢‘æ•°æ®
            original_shape = waveform.shape
            
            # ç»Ÿä¸€å¤„ç†ä¸º2Dæ ¼å¼ [channels, samples]
            if len(waveform.shape) == 1:
                # 1D: [samples] -> [1, samples]
                waveform = waveform.reshape(1, -1)
            elif len(waveform.shape) == 2:
                # 2D: æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬ç½®
                if waveform.shape[0] > waveform.shape[1]:
                    # å¯èƒ½æ˜¯ [samples, channels] -> [channels, samples]
                    waveform = waveform.T
            elif len(waveform.shape) == 3:
                # 3D: [batch, channels, samples] -> [channels, samples]
                if waveform.shape[0] == 1:
                    waveform = waveform.squeeze(0)
                else:
                    # å–ç¬¬ä¸€ä¸ªbatch
                    waveform = waveform[0]
            elif len(waveform.shape) > 3:
                # é«˜ç»´æ•°æ®ï¼šå°è¯•å‹ç¼©åˆ°2D
                # ä¿ç•™æœ€åä¸¤ä¸ªç»´åº¦ï¼Œå‹ç¼©å…¶ä»–ç»´åº¦
                new_shape = (-1, waveform.shape[-1])
                waveform = waveform.reshape(new_shape)
            
            # ç¡®ä¿æ˜¯2Dæ ¼å¼ [channels, samples]
            if len(waveform.shape) != 2:
                return ""
            
            channels, samples = waveform.shape
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_path = temp_file.name
            
            # å‡†å¤‡éŸ³é¢‘æ•°æ®ç”¨äºscipyä¿å­˜
            # scipy.io.wavfile.writeæœŸæœ›çš„æ ¼å¼æ˜¯ [samples, channels] æˆ– [samples] (å•å£°é“)
            if channels == 1:
                # å•å£°é“ï¼š[samples]
                audio_data_for_save = waveform[0]
            else:
                # å¤šå£°é“ï¼š[samples, channels]
                audio_data_for_save = waveform.T
            
            # è½¬æ¢ä¸º16ä½æ•´æ•°æ ¼å¼
            if audio_data_for_save.dtype != np.int16:
                # å‡è®¾è¾“å…¥æ˜¯æµ®ç‚¹æ•°åœ¨[-1, 1]èŒƒå›´å†…
                if audio_data_for_save.max() <= 1.0 and audio_data_for_save.min() >= -1.0:
                    audio_data_for_save = (audio_data_for_save * 32767).astype(np.int16)
                else:
                    # å¦‚æœä¸åœ¨[-1,1]èŒƒå›´ï¼Œè¿›è¡Œå½’ä¸€åŒ–
                    max_val = max(abs(audio_data_for_save.max()), abs(audio_data_for_save.min()))
                    if max_val > 0:
                        audio_data_for_save = (audio_data_for_save / max_val * 32767).astype(np.int16)
                    else:
                        audio_data_for_save = audio_data_for_save.astype(np.int16)
            
            # ä½¿ç”¨scipyä¿å­˜éŸ³é¢‘æ–‡ä»¶
            scipy.io.wavfile.write(temp_path, sample_rate, audio_data_for_save)
            
            return temp_path
            
        except ImportError:
            return ""
        except Exception as e:
            return ""

    def merge_videos(
        self,
        video_paths,
        output_filename: str,
        audio=None,
        video_paths_list=None,
        **kwargs
    ) -> Dict[str, Any]:
        
        try:
            # å¤„ç†éŸ³é¢‘è¾“å…¥
            temp_audio_path = ""
            if audio is not None:
                try:
                    temp_audio_path = self._save_audio_to_temp(audio)
                    if temp_audio_path:
                        audio_duration = self._get_audio_duration(audio)
                except Exception as e:
                    temp_audio_path = ""
            
            # ä¼˜å…ˆä½¿ç”¨åˆ—è¡¨è¾“å…¥ï¼Œå¦‚æœæä¾›çš„è¯
            if video_paths_list is not None:
                if hasattr(video_paths_list, '__iter__') and not isinstance(video_paths_list, str):
                    # å¤„ç†å¯è¿­ä»£å¯¹è±¡ï¼ˆåˆ—è¡¨ã€å…ƒç»„ã€é›†åˆç­‰ï¼‰ï¼Œä½†æ’é™¤å­—ç¬¦ä¸²
                    path_list = [str(path) for path in video_paths_list]
                    valid_paths = self._validate_video_files(path_list)
                else:
                    # å¦‚æœä¸æ˜¯å¯è¿­ä»£å¯¹è±¡ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                    valid_paths = self._validate_video_files([str(video_paths_list)])
            elif isinstance(video_paths, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æŒ‰è¡Œåˆ†å‰²
                path_list = [path.strip() for path in video_paths.split('\n') if path.strip()]
                if not path_list:
                    # å¦‚æœåˆ†å‰²åä¸ºç©ºï¼Œå°è¯•æŒ‰é€—å·åˆ†å‰²
                    path_list = [path.strip() for path in video_paths.split(',') if path.strip()]
                if not path_list:
                    # å¦‚æœè¿˜æ˜¯ä¸ºç©ºï¼Œå°†æ•´ä¸ªå­—ç¬¦ä¸²ä½œä¸ºå•ä¸ªè·¯å¾„
                    path_list = [video_paths.strip()]
                
                valid_paths = self._validate_video_files(path_list)
            elif hasattr(video_paths, '__iter__'):
                # å¤„ç†å¯è¿­ä»£å¯¹è±¡ï¼ˆåˆ—è¡¨ã€å…ƒç»„ã€é›†åˆç­‰å­—ç¬¦ä¸²åºåˆ—ï¼‰
                try:
                    path_list = [str(path) for path in video_paths]
                    valid_paths = self._validate_video_files(path_list)
                except Exception as e:
                    raise ValueError(f"Failed to process iterable video_paths: {e}")
            else:
                raise ValueError(f"video_paths must be a string or iterable, got {type(video_paths)}")
            
            if len(valid_paths) < 2:
                raise ValueError(f"At least 2 valid video files are required for merging, but only found {len(valid_paths)} valid files")
            
            # ç¡®å®šè¾“å‡ºç›®å½•å’Œæ–‡ä»¶è·¯å¾„
            output_dir = folder_paths.get_output_directory()
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            base_name, ext = os.path.splitext(output_filename)
            if not ext:
                ext = '.mp4'
            
            counter = 1
            final_filename = f"{base_name}_{counter:05}{ext}"
            output_path = os.path.join(output_dir, final_filename)
            
            while os.path.exists(output_path):
                counter += 1
                final_filename = f"{base_name}_{counter:05}{ext}"
                output_path = os.path.join(output_dir, final_filename)
            
            # æ‰§è¡Œè§†é¢‘åˆå¹¶
            total_duration = self._execute_merge(
                valid_paths, output_path, temp_audio_path
            )
            
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            if temp_audio_path and os.path.exists(temp_audio_path):
                try:
                    os.unlink(temp_audio_path)
                except Exception as e:
                    pass
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
                raise RuntimeError("Merged video file was not created or is empty")
            
            absolute_output_path = os.path.abspath(output_path)
            
            return {
                "ui": {},
                "result": (absolute_output_path,)
            }
            
        except Exception as e:
            # ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿæ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            if 'temp_audio_path' in locals() and temp_audio_path and os.path.exists(temp_audio_path):
                try:
                    os.unlink(temp_audio_path)
                except:
                    pass  # å¿½ç•¥æ¸…ç†æ—¶çš„é”™è¯¯
            
            raise RuntimeError(f"Video merge failed: {str(e)}")

    def _execute_merge(self, video_paths: List[str], output_path: str, 
                      temp_audio_path: str) -> float:
        """æ‰§è¡Œè§†é¢‘åˆå¹¶"""
        return self._merge_concat(video_paths, output_path, temp_audio_path)

    def _merge_concat(self, video_paths: List[str], output_path: str, 
                     temp_audio_path: str) -> float:
        """ä½¿ç”¨concatæ–¹æ³•æ— æŸåˆå¹¶è§†é¢‘ï¼ˆæ”¯æŒèƒŒæ™¯éŸ³é¢‘æ·»åŠ ï¼‰"""
        
        # éªŒè¯è¾“å…¥å‚æ•°
        if not video_paths:
            raise ValueError("No video paths provided for merging")
        
        import tempfile
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨ï¼ˆä½¿ç”¨UTF-8ç¼–ç ç¡®ä¿è·¯å¾„æ­£ç¡®å¤„ç†ï¼‰
        concat_file = None
        try:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
                concat_file = f.name
                for video_path in video_paths:
                    # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶æ­£ç¡®è½¬ä¹‰
                    abs_path = os.path.abspath(video_path)
                    f.write(f"file '{abs_path}'\n")
            
            # ç¬¬ä¸€æ­¥ï¼šæ— æŸåˆå¹¶è§†é¢‘ï¼ˆcopyæµï¼Œé¿å…é‡ç¼–ç ï¼‰
            cmd_video = [
                self.ffmpeg_path, "-y", 
                "-f", "concat", 
                "-safe", "0",
                "-i", concat_file,
                "-c", "copy",                    # å®Œå…¨æ— æŸå¤åˆ¶
                "-avoid_negative_ts", "make_zero",  # é¿å…æ—¶é—´æˆ³é—®é¢˜
                output_path
            ]
            
            result = subprocess.run(cmd_video, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise RuntimeError(f"è§†é¢‘åˆå¹¶å¤±è´¥:\n{result.stderr}")
            
            # ç¬¬äºŒæ­¥ï¼šå¦‚æœæä¾›äº†éŸ³é¢‘ï¼Œåˆå¹¶éŸ³è§†é¢‘
            if temp_audio_path and os.path.exists(temp_audio_path):
                # è·å–è§†é¢‘æ—¶é•¿ï¼Œç¡®ä¿éŸ³é¢‘ä¸è¶…è¿‡è§†é¢‘é•¿åº¦
                video_duration = self._get_video_duration(output_path)
                audio_duration = self._get_audio_duration_from_file(temp_audio_path)
                
                # å¦‚æœéŸ³é¢‘é•¿åº¦è¶…è¿‡è§†é¢‘é•¿åº¦ï¼Œè£å‰ªéŸ³é¢‘
                final_audio_path = temp_audio_path
                if audio_duration > video_duration:
                    final_audio_path = self._trim_audio_to_duration(temp_audio_path, video_duration)
                
                # åˆ›å»ºå¸¦éŸ³é¢‘çš„æœ€ç»ˆæ–‡ä»¶
                temp_output = output_path.replace(".mp4", "_with_audio.mp4")
                cmd_audio = [
                    self.ffmpeg_path, "-y",
                    "-i", output_path,           # å·²åˆå¹¶çš„è§†é¢‘
                    "-i", final_audio_path,      # éŸ³é¢‘æ–‡ä»¶
                    "-map", "0:v",               # æ˜ å°„è§†é¢‘æµ
                    "-map", "1:a",               # æ˜ å°„éŸ³é¢‘æµ
                    "-c:v", "copy",              # è§†é¢‘æµä¿æŒä¸å˜
                    "-c:a", "aac",               # éŸ³é¢‘ç¼–ç ä¸ºAAC
                    "-b:a", "128k",              # éŸ³é¢‘æ¯”ç‰¹ç‡
                    "-shortest",                 # ä»¥æœ€çŸ­çš„ä¸ºå‡†
                    temp_output
                ]
                
                result = subprocess.run(cmd_audio, capture_output=True, text=True)
                
                if result.returncode != 0:
                    raise RuntimeError(f"éŸ³é¢‘åˆå¹¶å¤±è´¥:\n{result.stderr}")
                
                # æ›¿æ¢åŸè§†é¢‘æ–‡ä»¶
                if os.path.exists(temp_output):
                    os.replace(temp_output, output_path)
            
            # è·å–æœ€ç»ˆè§†é¢‘æ—¶é•¿
            return self._get_video_duration(output_path)
            
        except Exception as e:
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if concat_file and os.path.exists(concat_file):
                try:
                    os.unlink(concat_file)
                except Exception:
                    pass

    def _get_audio_duration_from_file(self, audio_path: str) -> float:
        """ä»éŸ³é¢‘æ–‡ä»¶è·å–æ—¶é•¿"""
        try:
            cmd = [
                self.ffmpeg_path,
                "-i", audio_path,
                "-f", "null",
                "-"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # ä»stderrä¸­è§£ææ—¶é•¿ä¿¡æ¯
            for line in result.stderr.split('\n'):
                if 'Duration:' in line:
                    # æ ¼å¼: Duration: 00:01:23.45, start: 0.000000, bitrate: 1234 kb/s
                    duration_str = line.split('Duration: ')[1].split(',')[0]
                    # è§£æ HH:MM:SS.ss æ ¼å¼
                    time_parts = duration_str.split(':')
                    if len(time_parts) == 3:
                        hours = float(time_parts[0])
                        minutes = float(time_parts[1])
                        seconds = float(time_parts[2])
                        return hours * 3600 + minutes * 60 + seconds
            
            return 0.0
            
        except Exception as e:
            return 0.0

    def _trim_audio_to_duration(self, audio_path: str, target_duration: float) -> str:
        """è£å‰ªéŸ³é¢‘åˆ°æŒ‡å®šæ—¶é•¿"""
        try:
            import tempfile
            
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            trimmed_audio_path = os.path.join(temp_dir, f"trimmed_audio_{os.getpid()}.wav")
            
            cmd = [
                self.ffmpeg_path,
                "-i", audio_path,
                "-t", str(target_duration),  # è£å‰ªåˆ°æŒ‡å®šæ—¶é•¿
                "-c:a", "pcm_s16le",  # ä½¿ç”¨PCMç¼–ç ç¡®ä¿å…¼å®¹æ€§
                "-y", trimmed_audio_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                return audio_path  # è¿”å›åŸéŸ³é¢‘è·¯å¾„
            
            return trimmed_audio_path
            
        except Exception as e:
            return audio_path  # è¿”å›åŸéŸ³é¢‘è·¯å¾„

    def _get_video_duration(self, video_path: str) -> float:
        """è·å–è§†é¢‘æ—¶é•¿"""
        try:
            cmd = [
                self.ffmpeg_path,
                "-i", video_path,
                "-f", "null",
                "-"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # ä»stderrä¸­è§£ææ—¶é•¿ä¿¡æ¯
            for line in result.stderr.split('\n'):
                if 'Duration:' in line:
                    # æ ¼å¼: Duration: 00:01:23.45, start: 0.000000, bitrate: 1234 kb/s
                    duration_str = line.split('Duration: ')[1].split(',')[0]
                    # è§£æ HH:MM:SS.ss æ ¼å¼
                    time_parts = duration_str.split(':')
                    if len(time_parts) == 3:
                        hours = float(time_parts[0])
                        minutes = float(time_parts[1])
                        seconds = float(time_parts[2])
                        return hours * 3600 + minutes * 60 + seconds
            
            return 0.0
            
        except Exception as e:
            return 0.0

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "VideoCombineNode": VideoCombineNode,
    "VideoMergeNode": VideoMergeNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoCombineNode": "lian Video Combine ğŸ¬",
    "VideoMergeNode": "lian Video Merge ğŸï¸",
}